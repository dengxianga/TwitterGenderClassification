\section{Discussion}
Working on this gender-classification project gave our team a chance to reflect on what we have learned in class. Here is a short summary of things that have surprised us (or have taught us a lesson):
\begin{itemize}
\item With different feature sets (especially when they have various ranges and dimensions), feature selection and normalization have played an important role in improving the performances of our models. 
\item A huge part of this project is about trying various models, tuning their parameters and training with the right sets of features. Naive Bayes, for example, is around 40\% more accurate when using the Bernoulli features (representing appearance/ absence) instead of its frequency. However, it does not improve the performance of our ensemble method and was not included in our final system. Methods like KNN, GMM and K-means require careful feature selections and we did not get the right feature sets to make it work well. 
\item Logistic Regression worked surprisingly well even without feature selection. It is both accurate and fast. Boosting using hundreds of weak learners also surprised us in terms of its accuracy. SVMs were expected to perform well and they did.
\item Ensemble methods can really boost the performance with several classifiers with fair accuracies, while ideally theses classifiers disagree in many classifications (which means they capture different patterns).
\item Do not underestimate the size of PCA coefficients. 
\item Toolboxes can be helpful and tricky at the same time, therefore making assumptions is dangerous. Read the documents (and FAQ, watch out for some interesting features of liblinear and libsvm).
\item Last but not least, be careful with the required formats..
\end{itemize} 

