%% data loading:
%% Load the data first, see data_preprocess.m
tic
% load('train/genders_train.mat', 'genders_train');
% load('train/images_train.mat', 'images_train');
% load('train/image_features_train.mat', 'image_features_train');
% load('train/words_train.mat', 'words_train');
% load('test/images_test.mat', 'images_test');
% load('test/image_features_test.mat', 'image_features_test');
% load('test/words_test.mat', 'words_test');
% load('coef.mat', 'coef');
% load('scores.mat', 'scores');
% load('eigens.mat', 'eigens');
% Load the data first, see prepare_data.
if exist('genders_train','var')~= 1
prepare_data;
load('train/genders_train.mat', 'genders_train');
load('train/images_train.mat', 'images_train');
load('train/image_features_train.mat', 'image_features_train');
load('train/words_train.mat', 'words_train');
load('test/images_test.mat', 'images_test');
load('test/image_features_test.mat', 'image_features_test');
load('test/words_test.mat', 'words_test');
end

% Prepare/Load PCA-ed data,  
if exist('eigens','var')~= 1
    if exist('coef.mat','file') ~= 2 
        X = [words_train, image_features_train; words_test, image_features_test]; 
        [coef, scores, eigens] = pca(X);
        save('coef.mat', 'coef');
        save('scores.mat', 'scores');
        save('eigens.mat', 'eigens');
    else 
        load('coef.mat', 'coef');
        load('scores.mat', 'scores');
        load('eigens.mat', 'eigens');
    end
end



%% Play with SVM
% Ref: https://www.csie.ntu.edu.tw/~cjlin/papers/guide/guide.pdf

% Transform data to the format of an SVM package
% Vector of reals; 
% Scaling (avoid greater numerics domination)to [-1,1];
X = [words_train, image_features_train; words_test, image_features_test];
Y = genders_train;
% Conduct simple scaling on the data [-1,1]
Xnorm = -1 + 2.*(X - repmat(min(X),9995,1)./repmat(range(X),9995,1));
% Caution, remove uninformative NaN data % for nan - columns
Xcl = Xnorm(:,all(~isnan(Xnorm)));   

%% Test normailized PCA
% [coefNor, scoresNor, eigensNor] = pca(Xcl);
% Best number of PC for linear :320 ~ Comparable. 
disp('linear regression + cross-validation');
X = scores(1:n, 1:320);
[accuracy, Ypredicted, Ytest] = cross_validation(X, Y, folds, @linear_regression);
accuracy
mean(accuracy)
toc

% ----------logistic regression ~ slightly Better.
X = scoresNor(1:n, 1:3200);
addpath('./liblinear');
disp('logistic regression + cross-validation');
[accuracy, Ypredicted, Ytest] = cross_validation(X, Y, 4, @logistic);
accuracy
mean(accuracy)
toc
%

%%
%Consider the RBF kernel 
X = score(1:n;1:320);
k = @(x,x2) kernel_poly(x, x2, 1);
svm1 = kernel_libsvm(
[test_err ~] = kernel_libsvm(X, Y, Xtest, Ytest, k);
test_err 

%Use cross-validation to find the best parameter C and r 
%%
% X = scores(1:n, 1:300);

addpath('./libsvm');
disp('SVM + Cross-validation');
X = Xcl(1:n);
[accuracy, Ypredicted, Ytest] = cross_validation(X, Y, 4, @svm);
toc
accuracy
mean(accuracy)
toc

% Use the best parameter C and to train the whole training set
% Test
